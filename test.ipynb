{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC3 Complejidad O(n) sufix array\n",
    "\n",
    "def skew_rec(x : list[int], asize : int) -> list[int]:\n",
    "    \"Recursive skew SA construction algorithm.\"\n",
    "\n",
    "    SA12 = [i for i in range(len(x)) if i % 3 != 0]\n",
    "    \n",
    "    SA12 = radix3(x, asize, SA12)\n",
    "    new_alpha = collect_alphabet(x, SA12)\n",
    "    if len(new_alpha) < len(SA12):\n",
    "        # Recursively sort SA12.\n",
    "        # Construct the u string and compute its suffix array\n",
    "        u = build_u(x, new_alpha)\n",
    "        # For the recursion, remember that the real alphabet has\n",
    "        # two sentinels, so + 2\n",
    "        sa_u = skew_rec(u, len(new_alpha) + 2)\n",
    "        # Then map u's suffix array back to a sorted SA12\n",
    "        m = len(sa_u) // 2\n",
    "        SA12 = [u_idx(i, m) for i in sa_u if i != m]\n",
    "\n",
    "    # Special case if the last index is class 0. Then the\n",
    "    # following class 1 isn't there, but we should treat it\n",
    "    # as the smallest string in the class.\n",
    "    SA3 = ([len(x) - 1] if len(x) % 3 == 1 else []) + \\\n",
    "          [i - 1 for i in SA12 if i % 3 == 1]\n",
    "    SA3 = bucket_sort(x, asize, SA3)\n",
    "    return merge(x, SA12, SA3)\n",
    "\n",
    "def skew(x : str) -> list[int]:\n",
    "    \"Skew algorithm for a string.\"\n",
    "    # The skew_rec() function wants a list of integers,\n",
    "    # so we convert the string in the first call.\n",
    "    # It is only because of the safe_idx() hack that we\n",
    "    # need to convert the string; without it, we could work\n",
    "    # with both str and list[int], but the sentinel we generate\n",
    "    # is int, and we have to compare letters, so all letters must\n",
    "    # then be int.\n",
    "    # I am assuming that the alphabet size is 256 here, although\n",
    "    # of course it might not be. It is a simplification instead of\n",
    "    # remapping the string.\n",
    "    return skew_rec([ord(y) for y in x], 256)\n",
    "\n",
    "\n",
    "def safe_idx(x : list[int], i : int) -> int:\n",
    "    \"Hack to get zero if we index beyond the end.\"\n",
    "    return 0 if i >= len(x) else x[i]\n",
    "\n",
    "def symbcount(x : list[int], asize : int) -> list[int]:\n",
    "    \"Count how often we see each character in the alphabet.\"\n",
    "    # This is what collections.Counter does, but we need the\n",
    "    # alphabet to be sorted integers, so we do it manually.\n",
    "    counts = [0] * asize\n",
    "    for c in x:\n",
    "        counts[c] += 1\n",
    "    return counts\n",
    "\n",
    "def cumsum(counts : list[int]) -> list[int]:\n",
    "    \"Compute the cumulative sum from the character count.\"\n",
    "    res, acc = [0] * len(counts), 0\n",
    "    for i, k in enumerate(counts):\n",
    "        res[i] = acc\n",
    "        acc += k\n",
    "    return res\n",
    "\n",
    "def bucket_sort(x : list[int], asize : int,\n",
    "                idx : list[int], offset : int = 0) -> list[int]:\n",
    "    \"Sort indices in idx according to x[i + offset].\"\n",
    "    sort_symbs = [safe_idx(x, i + offset) for i in idx]\n",
    "    counts = symbcount(sort_symbs, asize)\n",
    "    buckets = cumsum(counts)\n",
    "    out = [None] * len(idx)\n",
    "    for i in idx:\n",
    "        bucket = safe_idx(x, i + offset)\n",
    "        out[buckets[bucket]] = i\n",
    "        buckets[bucket] += 1\n",
    "    return out\n",
    "\n",
    "def radix3(x : list[int], asize : int, idx : list[int]) -> list[int]:\n",
    "    \"Sort indices in idx according to their first three letters in x.\"\n",
    "    idx = bucket_sort(x, asize, idx, 2)\n",
    "    idx = bucket_sort(x, asize, idx, 1)\n",
    "    return bucket_sort(x, asize, idx)\n",
    "\n",
    "TRIPLET = tuple[int,int,int]\n",
    "TRIPLET_DICT = dict[TRIPLET,int]\n",
    "\n",
    "def triplet(x : list[int], i : int) -> TRIPLET:\n",
    "    \"Extract the triplet (x[i],x[i+1],x[i+2]).\"\n",
    "    return (safe_idx(x, i), safe_idx(x, i + 1), safe_idx(x, i + 2))\n",
    "\n",
    "def collect_alphabet(x : list[int], idx : list[int]) -> TRIPLET_DICT:\n",
    "    \"Map the triplets starting at idx to a new alphabet.\"\n",
    "    # I use 0 for the terminal sentinel and 1 for the \n",
    "    # separator, so I start the alphabet at 2, thus the + 2 later.\n",
    "    # I'm using a dictionary for the alphabet, but you can build\n",
    "    # it more efficiently by looking at the previous triplet in the\n",
    "    # sorted SA12. It won't affect the asymptotic running time,\n",
    "    # though.\n",
    "    alpha = {}\n",
    "    for i in idx:\n",
    "        trip = triplet(x, i)\n",
    "        if trip not in alpha:\n",
    "            alpha[trip] = len(alpha) + 2 # +2 to reserve sentinels\n",
    "    return alpha\n",
    "\n",
    "def build_u(x : list[int], alpha : TRIPLET_DICT) -> list[int]:\n",
    "    \"Construct u string, using 1 as central sentinel.\"\n",
    "    # By putting the i % 3 == 1 indices first, we know that the central\n",
    "    # sentinel will always be at len(u) // 2.\n",
    "    return [ *(alpha[triplet(x, i)] for i in range(1, len(x), 3)),\n",
    "           1,\n",
    "             *(alpha[triplet(x, i)] for i in range(2, len(x), 3)) ]\n",
    "\n",
    "\n",
    "\n",
    "def u_idx(i : int, m : int) -> int:\n",
    "    \"Map indices in u back to indices in the original string.\"\n",
    "    if i < m: return 1 + 3 * i\n",
    "    else: return 2 + 3 * (i - m - 1)\n",
    "    \n",
    "    \n",
    "def merge(x : list[int], SA12 : list[int], SA3 : list[int]) -> list[int]:\n",
    "    \"Merge the suffixes in sorted SA12 and SA3.\"\n",
    "    # I'm using a dict here, but you can use a list with a little\n",
    "    # arithmetic\n",
    "    ISA = { SA12[i]: i for i in range(len(SA12)) }\n",
    "    SA = []\n",
    "    i, j = 0, 0\n",
    "    while i < len(SA12) and j < len(SA3):\n",
    "        if less(x, SA12[i], SA3[j], ISA):\n",
    "            SA.append(SA12[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            SA.append(SA3[j])\n",
    "            j += 1\n",
    "    SA.extend(SA12[i:])\n",
    "    SA.extend(SA3[j:])\n",
    "    return SA\n",
    "\n",
    "def less(x : list[int], i : int, j : int, ISA : dict[int,int]) -> bool:\n",
    "    \"Check if x[i:] < x[j:] using the inverse suffix array for SA12.\"\n",
    "    a, b = safe_idx(x, i), safe_idx(x, j)\n",
    "    if a < b: return True\n",
    "    if a > b: return False\n",
    "    if i % 3 != 0 and j % 3 != 0: return ISA[i] < ISA[j]\n",
    "    return less(x, i + 1, j + 1, ISA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_common_substrings_top5_with_suffix_arrays(suffix_array1, suffix_array2, text1, text2):\n",
    "    \"\"\"\n",
    "    Encuentra las 5 subcadenas comunes más largas entre dos textos utilizando arrays de sufijos\n",
    "    y evitando superposiciones.\n",
    "    \"\"\"\n",
    "    def common_substring_from_suffixes(suffix1, suffix2):\n",
    "        \"\"\"\n",
    "        Calcula la longitud de la subcadena común que comienza en los índices especificados por los sufijos.\n",
    "        \"\"\"\n",
    "        i, j = suffix1, suffix2\n",
    "        common_length = 0\n",
    "        while i < len(text1) and j < len(text2) and text1[i] == text2[j]:\n",
    "            common_length += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        return text1[suffix1:suffix1 + common_length]\n",
    "\n",
    "    substrings = []\n",
    "    used_ranges_text1 = set()\n",
    "\n",
    "    for suffix1 in suffix_array1:\n",
    "        for suffix2 in suffix_array2:\n",
    "            substring = common_substring_from_suffixes(suffix1, suffix2)\n",
    "            if substring and len(substring) > 0:\n",
    "                # Verificar que la subcadena no esté superpuesta con rangos previos\n",
    "                end_pos = suffix1 + len(substring)\n",
    "                if all(not (suffix1 < r[1] and end_pos > r[0]) for r in used_ranges_text1):\n",
    "                    substrings.append((substring, len(substring)))\n",
    "                    used_ranges_text1.add((suffix1, end_pos))\n",
    "                    # Ordenar y mantener solo las 5 subcadenas más largas\n",
    "                    substrings = sorted(substrings, key=lambda x: -x[1])[:5]\n",
    "\n",
    "    # Extraer solo las subcadenas (sin longitud)\n",
    "    return [s[0] for s in substrings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las 5 subcadenas comunes más largas y únicas encontradas: ['es', ' ', ' ', ' ', ' ']\n",
      "[20, 8, 16, 4, 14, 0, 3, 27, 10, 25, 30, 12, 21, 26, 2, 9, 28, 13, 1, 18, 6, 17, 5, 22, 29, 11, 23, 24, 19, 7, 15]\n",
      "[8, 21, 4, 17, 15, 0, 3, 9, 12, 26, 25, 2, 10, 14, 24, 1, 28, 6, 19, 22, 29, 13, 23, 27, 5, 18, 11, 7, 20, 16]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hola soy mateo y soy estudiante\"\n",
    "text2 = \"Hola soy alvaro y soy profesor\"\n",
    "suffix_array1 = skew(text1)  # Array de sufijos de text1 (debes generarlo previamente)\n",
    "suffix_array2 = skew(text2)   # Array de sufijos de text2\n",
    "\n",
    "substrings = largest_common_substrings_top5_with_suffix_arrays(suffix_array1, suffix_array2, text1, text2)\n",
    "print(f\"Las 5 subcadenas comunes más largas y únicas encontradas: {substrings}\")\n",
    "print(suffix_array1)\n",
    "print(suffix_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de similitud: 86.11111111111111 %\n"
     ]
    }
   ],
   "source": [
    "def lcs_non_overlapping(s1, s2):\n",
    "    len_s1, len_s2 = len(s1), len(s2)\n",
    "    dp = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "\n",
    "    for i in range(1, len_s1 + 1):\n",
    "        for j in range(1, len_s2 + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "\n",
    "    i, j = len_s1, len_s2\n",
    "    lcs_length_sum = 0\n",
    "    while i > 0 and j > 0:\n",
    "        if s1[i - 1] == s2[j - 1]:\n",
    "            match_length = dp[i][j] - dp[i - 1][j - 1]\n",
    "            lcs_length_sum += match_length\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif dp[i - 1][j] >= dp[i][j - 1]:\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "\n",
    "    return lcs_length_sum\n",
    "\n",
    "def similarity_percentage(text1, text2):\n",
    "    lcs_length_sum = lcs_non_overlapping(text1, text2)\n",
    "    max_len = max(len(text1), len(text2))\n",
    "    similarity = (lcs_length_sum / max_len) * 100\n",
    "    return similarity\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stadisticsBase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
